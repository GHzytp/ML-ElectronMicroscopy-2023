{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hideOutput": true,
    "hidePrompt": false
   },
   "source": [
    "<font size = \"5\"> **[Correcting Image Distortions](0_Correcting_Image_Distortions.ipynb)** </font>\n",
    "\n",
    "<hr style=\"height:1px;border-top:4px solid #FF8200\" />\n",
    "\n",
    "by \n",
    "\n",
    "Gerd Duscher\n",
    "\n",
    "Materials Science & Engineering<br>\n",
    "Joint Institute of Advanced Materials<br>\n",
    "The University of Tennessee, Knoxville\n",
    "\n",
    "and \n",
    "\n",
    "Matthew. F. Chisholm\n",
    "\n",
    "Center of Nanophase Materials<br>\n",
    "Oak Ridge National Laboratory\n",
    "\n",
    "# Undistortion and Registration of Image-Stacks\n",
    "\n",
    "We use this notebook **only** for a stacks of images for which we have a different stack where the distortion matrix is already determined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## First we import the usual libraries\n",
    "Please visit the  [Introductory notebook](0_Correcting_Image_Distortions.ipynb) to install ``pyTEMlib``and for more information on the used packages.\n",
    "\n",
    "You'll need at least pyTEMlib version 0.05.2020.0 .\n",
    "\n",
    "Run the code cell below to load all the python packages that we use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib and numpy\n",
    "#                       use \"inline\" instead of \"notebook\" for non-interactive plots\n",
    "%pylab --no-import-all notebook\n",
    "\n",
    "\n",
    "# Import libraries from the book\n",
    "\n",
    "import pyTEMlib\n",
    "import file_tools  as ft     # File input/ output library\n",
    "import image_tools as it\n",
    "\n",
    "# For archiving reasons it is a good idea to print the version numbers out at this point\n",
    "print('pyTEM version: ',pyTEMlib.__version__)\n",
    "\n",
    "__notebook__ = 'Undistorted_Registration'\n",
    "__notebook_version__ = '2020_06_09'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Load an image stack :\n",
    "\n",
    "Please, load an image stack. <br>\n",
    "\n",
    "A stack of images is used to reduce noise, but for an added image the images have to be aligned to compensate for drift and other microscope instabilities.\n",
    "\n",
    "Note that the **open file dialog** might not apear in the foreground!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Open_Nion_Directory = True\n",
    "\n",
    "try: ### Close any h5_file that may be left open\n",
    "    h5_file.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "### Open file Dialog\n",
    "import importlib\n",
    "importlib.reload(ft)\n",
    "\n",
    "if Open_Nion_Directory:\n",
    "    nion_selection = ft.nion_directory()\n",
    "else:\n",
    "    %gui qt5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Image Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Load file\n",
    "try:\n",
    "    h5_file.close()\n",
    "except: \n",
    "    pass\n",
    "if Open_Nion_Directory:\n",
    "    try:\n",
    "        h5_file = nion_selection.h5_file\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    h5_file = ft.h5_open_file()#os.path.join(current_directory,filename))\n",
    "\n",
    "current_channel = h5_file['Measurement_000/Channel_000']\n",
    "current_dataset = current_channel['nDim_Data']\n",
    "\n",
    "if current_channel['data_type'][()] != 'image_stack':\n",
    "    print(f\"Please load an image stack for this notebook, this is an {current_channel['data_type'][()]}\")\n",
    "    \n",
    "\n",
    "print('Previous analysis of ',current_dataset.attrs['title'])        \n",
    "for key in current_channel:\n",
    "    if 'Log' in key:\n",
    "        if 'analysis' in current_channel[key].keys():\n",
    "            print(f\"{key} includes analysis: {current_channel[key]['analysis'][()]}\")\n",
    "            \n",
    "view = ft.h5_plot(current_dataset)  # note this needs a view reference for interaction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image with Distortion Matrix\n",
    "\n",
    "Here we need a file file for which a distortion matrix has been determined. \n",
    "We use that distortion matrix to remove the distortion from the current file. \n",
    "\n",
    "Please note that the scale will change to an **absolute scale**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(ft.config_path+'\\path.txt','r')\n",
    "path = fp.read()\n",
    "fp.close()\n",
    "distortion_selection = ft.nion_directory(path, extension=['hf5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load file\n",
    "\n",
    "distort_file  = distortion_selection.h5_file\n",
    "current_distort_channel = distort_file['Measurement_000/Channel_000']\n",
    "\n",
    "found_distortion_matrix = False  \n",
    "\n",
    "for key in current_distort_channel:\n",
    "    if 'Log' in key:\n",
    "        if 'analysis' in current_distort_channel[key]:\n",
    "            if  'Distortion' in current_distort_channel[key]['analysis'][()]:\n",
    "                distortion_tags  = current_distort_channel[key]\n",
    "                found_distortion_matrix = True\n",
    "                d_scaleX = current_distort_channel[key]['scale_x'][()]\n",
    "                d_scaleY = current_distort_channel[key]['scale_y'][()]\n",
    "                distortion_matrix = current_distort_channel[key]['distortion_matrix'][()]\n",
    "                if 'distortion_crop' in current_distort_channel[key]: \n",
    "                    distortion_crop = current_distort_channel[key]['distortion_crop'][()]\n",
    "            if 'Rigid Registration' == current_distort_channel[key]['analysis'][()]:\n",
    "                distortion_crop = current_distort_channel[key]['Rigid_registration_crop'][()]\\\n",
    "            \n",
    "if found_distortion_matrix:\n",
    "    print('found distortion matrix')\n",
    "    name = 'Distortion_Matrix'\n",
    "    distortion_matrix_original = distortion_matrix.copy()\n",
    "else:    \n",
    "    print('No distortion matrix found!! We need a file with a distortion matrix to proceed!!!')\n",
    "distortion_filename =  distort_file.filename   \n",
    "distort_file.close()\n",
    "print(distortion_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(current_distort_channel[key]['analysis'][()])\n",
    "print(distortion_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Distortion Matrix\n",
    "This is not necessary but allows for a quick check on the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Visualize Distortion Matrix ( check whether you got all pixels)\n",
    "difference = distortion_matrix[:,:2]-distortion_matrix[:,2:]\n",
    "distance_image = np.zeros(current_dataset.shape[1:])\n",
    "angle_image = np.zeros(current_dataset.shape[1:])\n",
    "\n",
    "distance_image[(distortion_matrix[:,0].astype(int),distortion_matrix[:,1].astype(int))] = np.linalg.norm(difference, axis =1)\n",
    "angle_image[(distortion_matrix[:,0].astype(int),distortion_matrix[:,1].astype(int))] = np.degrees(np.arctan2(difference[:,1],difference[:,0]))\n",
    "             \n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "fig.suptitle('Distortion Matrix in Polar Coordinates')\n",
    "\n",
    "ax[0].set_title('norm')\n",
    "norm_fig = ax[0].imshow(distance_image*d_scaleX*1000)\n",
    "fig.colorbar(norm_fig, ax=ax[0] , label = 'distance [pm]')\n",
    "\n",
    "ax[1].set_title('angle')\n",
    "angle_fig = ax[1].imshow(angle_image,cmap = 'twilight')\n",
    "fig.colorbar(angle_fig, ax=ax[1], label = 'angle [$^o$]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "###  Input stack data\n",
    "We put all the input data into a dictionary named tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    " ## spatial data\n",
    "d_crop = distortion_crop\n",
    "tags = {}\n",
    "tags['sizeX'] = current_dataset.shape[1]\n",
    "tags['sizeY'] = current_dataset.shape[2]\n",
    "tags['scaleX'] = d_scaleX\n",
    "tags['scaleY'] = d_scaleY\n",
    "tags['crop'] = distortion_crop\n",
    "tags['extent'] = it.make_extent(current_dataset.shape[1:],tags['scaleX'],tags['scaleY'])\n",
    "    \n",
    "d_crop = distortion_crop\n",
    "data_cube = np.array(current_dataset[:,d_crop[0]:d_crop[1],d_crop[2]:d_crop[3]])\n",
    "print(data_cube.shape, current_dataset.shape)\n",
    "\n",
    "## reduce distortion matrix to same croped image\n",
    "distortion_matrix = distortion_matrix[np.where(distortion_matrix[:,0]<data_cube.shape[1])]\n",
    "distortion_matrix = distortion_matrix[np.where(distortion_matrix[:,1]<data_cube.shape[2])]\n",
    "distortion_matrix = distortion_matrix[np.where(distortion_matrix[:,0]>0)]\n",
    "distortion_matrix = distortion_matrix[np.where(distortion_matrix[:,1]>0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistort Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(it)\n",
    "\n",
    "interpolated = it.undistort_stack(distortion_matrix, data_cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop interpolated stack\n",
    "\n",
    "#### Choose Area \n",
    "Select the area that contains the atoms without rim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import  RectangleSelector\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(interpolated[0].T,origin = 'upper')\n",
    "selector = RectangleSelector(plt.gca(), None,interactive=True , drawtype='box')  # gca get current axis (plot)\n",
    "\n",
    "selector.to_draw.set_visible(True)\n",
    "radius = interpolated.shape[1]/2.1\n",
    "center = np.array(interpolated[0].shape)/2\n",
    "\n",
    "selector.extents = (center[0]-radius,center[0]+radius,center[1]-radius,center[1]+radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax = selector.extents\n",
    "print(selector.extents)\n",
    "reduced_stack= interpolated[:,int(xmin): int(xmax), int(ymin): int(ymax)]\n",
    "print(interpolated.min())\n",
    "reduced_stack[np.isnan(reduced_stack)]=0.\n",
    "print(reduced_stack.shape)\n",
    "extent = (xmin, xmax, ymax, ymin )\n",
    "plt.figure()\n",
    "plt.imshow(reduced_stack[0].T, interpolation='nearest',cmap='gray', extent = extent, origin = 'upper');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Complete Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Log Undistorted Stack\n",
    "out_tags = {}\n",
    "out_tags['notebook']= __notebook__ \n",
    "out_tags['notebook_version']= __notebook_version__\n",
    "out_tags['interpolation_crop'] = [xmin, xmax, ymin, ymax]\n",
    "out_tags['data'] = reduced_stack\n",
    "out_tags['data_type'] = 'image_stack'\n",
    "out_tags['name'] = 'Remove Distortion'\n",
    "out_tags['distortion_filename'] = distortion_filename\n",
    "out_tags['scale_x'] = d_scaleX ## needs to be specfied because different from loaded spectrum\n",
    "out_tags['scale_y'] = d_scaleY ## is now the one from distortion matrix\n",
    "\n",
    "### scale NOT RIGHT\n",
    "stack_group = ft.add_registration(current_channel, out_tags)\n",
    "\n",
    "## Do all of registration\n",
    "notebook_tags ={}\n",
    "notebook_tags['notebook']= __notebook__ \n",
    "notebook_tags['notebook_version']= __notebook_version__\n",
    "notebook_tags['scale_x'] = d_scaleX\n",
    "notebook_tags['scale_y'] = d_scaleY\n",
    "current_dataset = stack_group['nDim_Data']\n",
    "stack_group = it.complete_registration(current_dataset, current_channel, notebook_tags)\n",
    "\n",
    "h5_file.flush()\n",
    "\n",
    "for key in current_channel:\n",
    "    if 'Log' in key:\n",
    "        if 'analysis' in current_channel[key]:\n",
    "            print(f\"{key} includes analysis: {current_channel[key]['analysis'][()]}\")\n",
    "plot = ft.h5_plot(stack_group['nDim_Data'])\n",
    "print(h5_file.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in current_channel:\n",
    "    if 'Log' in key:\n",
    "        if 'analysis' in current_channel[key]:\n",
    "            if 'Rigid Registration' == current_channel[key]['analysis'][()]:\n",
    "                drift_channel = current_channel[key]\n",
    "                \n",
    "drift = drift_channel['Rigid_registration_drift']\n",
    "polynom_degree = 2 # 1 is linear fit, 2 is parabolic fit, ...\n",
    "\n",
    "x = np.linspace(0,drift.shape[0]-1,drift.shape[0])\n",
    "\n",
    "line_fit_x = np.polyfit(x, drift[:,0], polynom_degree)\n",
    "poly_x = np.poly1d(line_fit_x)\n",
    "line_fit_y = np.polyfit(x, drift[:,1], polynom_degree)\n",
    "poly_y = np.poly1d(line_fit_y)\n",
    "\n",
    "plt.figure()\n",
    "plt.axhline(color = 'gray')\n",
    "plt.plot(x, drift[:,0], label = 'drift x')\n",
    "plt.plot(x, drift[:,1], label = 'drift y')\n",
    "plt.plot(x, poly_x(x),  label = 'fit_drift_x')\n",
    "plt.plot(x, poly_y(x),  label = 'fit_drift_y')\n",
    "\n",
    "plt.legend();\n",
    "ax_pixels = plt.gca()\n",
    "ax_pixels.step(1, 1)\n",
    "for dim in current_dataset.dims:\n",
    "    if dim.label == 'x': scaleX = (dim[0][1]-dim[0][0])*1000.  #in pm\n",
    "\n",
    "ax_pm = ax_pixels.twinx()\n",
    "x_1, x_2 = ax_pixels.get_ylim()\n",
    "\n",
    "ax_pm.set_ylim(x_1*scaleX, x_2*scaleX)\n",
    "\n",
    "ax_pixels.set_ylabel('drift [pixels]')\n",
    "ax_pm.set_ylabel('drift [pm]')\n",
    "ax_pixels.set_xlabel('image number');\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h5_file.filename)\n",
    "h5_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open this file now in the [Strain Analysis](5_strain_analysis.ipynb) notebook.  \n",
    "\n",
    "Or if something went wrong go through the notebook step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Step by Step\n",
    "\n",
    "If this is an image stack we need to register and add the images. \n",
    "\n",
    "If this is not an image stack, we just take whatever image you opened.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rigid Registration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "stack = np.transpose(reduced_stack, axes=(0,1,2) )\n",
    "\n",
    "RigReg ,drift = it.Rigid_Registration(stack)\n",
    "\n",
    "RigReg_crop,crop  = it.crop_image_stack(RigReg, drift)\n",
    "    \n",
    "\n",
    "RigReg_image = np.sum(RigReg_crop, axis=2)\n",
    "    \n",
    "im = RigReg_image\n",
    "plt.figure()\n",
    "#plt.title(current_channel['title'][()] )\n",
    "plt.imshow(im.T,extent = tags['extent'], origin = 'upper');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Quality of Rigid Registration\n",
    "\n",
    "First we fit a polynom of degree **polynom_degree** onto the drift of x and y separately.\n",
    "\n",
    "The fit helps to discriminate outlayers (which then could be excluded, fixed, ... we did not had this problem for a while)\n",
    "\n",
    "In a cell below, the second fit can be used to correct the drift of the outlayer images in the stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom_degree = 2 # 1 is linear fit, 2 is parabolic fit, ...\n",
    "\n",
    "max_drift = 4 ## pixels\n",
    "\n",
    "x = np.linspace(0,drift.shape[0]-1,drift.shape[0])\n",
    "\n",
    "line_fit_x = np.polyfit(x, drift[:,0], polynom_degree)\n",
    "poly_x = np.poly1d(line_fit_x)\n",
    "line_fit_y = np.polyfit(x, drift[:,1], polynom_degree)\n",
    "poly_y = np.poly1d(line_fit_y)\n",
    "\n",
    "difference_drift = np.zeros(drift.shape)\n",
    "difference_drift[:,0] = np.abs(drift[:,0] - poly_x(x))\n",
    "difference_drift[:,1] = np.abs(drift[:,1] - poly_y(x))\n",
    "\n",
    "stable_images = np.all(difference_drift<4  ,axis=1) \n",
    "\n",
    "line_fit_x = np.polyfit(x*stable_images, drift[:,0]*stable_images, polynom_degree)\n",
    "poly_x = np.poly1d(line_fit_x)\n",
    "line_fit_y = np.polyfit(x*stable_images, drift[:,1]*stable_images, polynom_degree)\n",
    "poly_y = np.poly1d(line_fit_y)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.axhline(color = 'gray')\n",
    "plt.plot(x, drift[:,0], label = 'drift x')\n",
    "plt.plot(x, drift[:,1], label = 'drift y')\n",
    "\n",
    "#plt.plot(x, np.rint(drift[:,0]), label = 'pixel drift x')\n",
    "#plt.plot(x, np.rint(drift[:,1]), label = 'pixel drift y')\n",
    "\n",
    "\n",
    "plt.plot(x, poly_x(x),  label = 'fit_drift_x')\n",
    "plt.plot(x, poly_y(x),  label = 'fit_drift_y')\n",
    "\n",
    "outlayer = []\n",
    "remove =[]\n",
    "for i in range(len(stable_images)):\n",
    "    if not stable_images[i]:\n",
    "        plt.scatter(x[i],0, color='red')#, label='outlayers')\n",
    "        print(f'image {x[i]}: estimated drift x: {poly_x(x[i]):.2f}, y: {poly_y(x[i]):.2f}')\n",
    "        outlayer.append([i,poly_x(x[i]),poly_y(x[i])])\n",
    "        remove.append(i)\n",
    "\n",
    "plt.legend();\n",
    "ax_pixels = plt.gca()\n",
    "ax_pixels.step(1, 1)\n",
    "\n",
    "ax_pm = ax_pixels.twinx()\n",
    "x_1, x_2 = ax_pixels.get_ylim()\n",
    "scaleX = tags['scaleX']*1000\n",
    "ax_pm.set_ylim(x_1*scaleX, x_2*scaleX)\n",
    "\n",
    "ax_pixels.set_ylabel('drift [pixels]')\n",
    "ax_pm.set_ylabel('drift [pm]')\n",
    "ax_pixels.set_xlabel('image number');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Log Rigid Registration\n",
    "\n",
    "please note that the last used of the two above options is stored.\n",
    "Also we crop the stack and the summed image now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "out_tags = {}\n",
    "out_tags['analysis'] = 'Rigid Registration Undistorted'\n",
    "out_tags['notebook']= __notebook__ \n",
    "out_tags['notebook_version']= __notebook_version__\n",
    "\n",
    "out_tags['data_type'] = 'image_stack'\n",
    "out_tags['data'] = RigReg_crop\n",
    "\n",
    "out_tags['Rigid_registration_drift']=drift\n",
    "out_tags['Rigid_registration_crop'] = crop\n",
    "\n",
    "out_tags['spatial_origin_x'] = 0.\n",
    "out_tags['spatial_origin_y'] = 0.\n",
    "out_tags['spatial_scale_x'] = tags['scaleX']\n",
    "out_tags['spatial_scale_y'] = tags['scaleY']\n",
    "out_tags['spatial_size_x'] = RigReg_image.shape[0]\n",
    "out_tags['spatial_size_y'] = RigReg_image.shape[1]\n",
    "out_tags['spatial_units'] = 'nm'\n",
    "\n",
    "\n",
    "## Log data\n",
    "out_tags['name'] = 'rigid_registration_undistorted'\n",
    "out_tags['title'] = out_tags['name']\n",
    "stack_channel = ft.log_results(current_channel, out_tags)\n",
    "\n",
    "\n",
    "current_dataset = stack_channel['nDim_Data']\n",
    "view = ft.h5_plot(current_dataset)  # note this needs a view reference for interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file.flush()\n",
    "print(h5_file.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Rigid Registration\n",
    "\n",
    "Here we use the **Diffeomorphic Demon Non-Rigid Registration** as provided by **simpleITK**.  \n",
    "\n",
    "Please Cite: \n",
    "* [simpleITK](http://www.simpleitk.org/SimpleITK/project/parti.html)\n",
    "    \n",
    "    and\n",
    "    \n",
    "* [T. Vercauteren, X. Pennec, A. Perchant and N. Ayache *Diffeomorphic Demons Using ITK\\'s Finite Difference Solver Hierarchy* The Insight Journal, 2007](http://hdl.handle.net/1926/510)\n",
    "\n",
    "Please check Cite this article\n",
    "\n",
    "[Yankovich, A., Berkels, B., Dahmen, W. et al. Picometre-precision analysis of scanning transmission electron microscopy images of platinum nanocatalysts. Nat Commun 5, 4155 (2014)] (https://doi.org/10.1038/ncomms5155)\n",
    "\n",
    "\n",
    "This can take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "non_rigid_registered = it.DemonReg(current_dataset)\n",
    "\n",
    "DemReg_image = np.sum(non_rigid_registered, axis=2)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(DemReg_image.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "### Log Non-Rigid Registration\n",
    "\n",
    "please note that you can always delete a **Log** group with:<br>\n",
    "*del current_channel['Log_001']*  or whatever LOG number you want to get rid off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "out_tags={}\n",
    "\n",
    "out_tags['analysis']= 'Non-Rigid Registration Undistorted'\n",
    "out_tags['notebook']= __notebook__ \n",
    "out_tags['notebook_version']= __notebook_version__\n",
    "\n",
    "out_tags['data'] = non_rigid_registered\n",
    "out_tags['data_type'] = 'image_stack'\n",
    "    \n",
    "out_tags['spatial_origin_x'] = 0.\n",
    "out_tags['spatial_origin_y'] = 0.\n",
    "out_tags['spatial_scale_x'] = tags['scaleX']\n",
    "out_tags['spatial_scale_y'] = tags['scaleY']\n",
    "out_tags['spatial_size_x'] = DemReg_image.shape[0]\n",
    "out_tags['spatial_size_y'] = DemReg_image.shape[1]\n",
    "out_tags['spatial_units'] = 'nm'\n",
    "\n",
    "\n",
    "out_tags['name'] = 'non-rigid_registration_undistorted'\n",
    "out_tags['title'] = out_tags['name']\n",
    "\n",
    "stack_channel = ft.log_results(current_channel, out_tags)\n",
    "\n",
    "for key in current_channel:\n",
    "    if 'Log' in key:\n",
    "        if 'analysis' in current_channel[key]:\n",
    "            print(f\"{key} includes analysis: {current_channel[key]['analysis'][()]}\")\n",
    "\n",
    "plot = ft.h5_plot(stack_channel['nDim_Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## Close File\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open this file now in the [Strain Analysis](5_strain_analysis.ipynb) notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": "4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
